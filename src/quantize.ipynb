{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "from ner_tokenizer_bio import NER_tokenizer_BIO\n",
    "from bert_for_token_classification_pl import BertForTokenClassification_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_PATH     = './model/epoch=4-step=660.ckpt'\n",
    "TOKENIZER_PATH      = './model/iot-nlu-tokenizer'\n",
    "ONNX_FILE_PATH      = './model/iot-nlu.onnx'\n",
    "ONNX_INT8_FILE_PATH = './model/iot-nlu-ui8.onnx'\n",
    "\n",
    "# インテントの種類数 (None=0, LED_ON=1, LED_OFF=2, READ_THERMO=3, OPEN=4, CLOSE=5, SET_TEMP=6)\n",
    "NUM_INTENT_LABELS = 7\n",
    "\n",
    "# スロットの種類数 (COL=1, COLLTDEV=2, LOC=3, ONOFFDEV=4, OPENABLE=5, TEMPDEV=6, TEMPERTURE_NUM=7, THMDEV=8)\n",
    "NUM_ENTITY_TYPE   = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザのロード\n",
    "# 固有表現のカテゴリーの数`num_entity_type`を入力に入れる必要がある。\n",
    "tokenizer = NER_tokenizer_BIO.from_pretrained(\n",
    "    TOKENIZER_PATH,\n",
    "    num_entity_type=NUM_ENTITY_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export plain onnx to ui8 onnx\n",
    "quantize_dynamic(\n",
    "    ONNX_FILE_PATH,\n",
    "    ONNX_INT8_FILE_PATH,\n",
    "    weight_type=QuantType.QUInt8,\n",
    ")\n",
    "\n",
    "def print_sizel(file_path):\n",
    "    print('Size (MB):', os.path.getsize(file_path)/1e6)\n",
    "\n",
    "print_sizel(ONNX_FILE_PATH)\n",
    "print_sizel(ONNX_INT8_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "dataset = json.load(open('data/nlp_data.json','r'))\n",
    "\n",
    "# カテゴリーをラベルに変更、文字列の正規化する。\n",
    "for sample in dataset:\n",
    "    sample['text'] = unicodedata.normalize('NFKC', sample['text'])\n",
    "\n",
    "# データセットの分割\n",
    "random.shuffle(dataset)\n",
    "dataset = dataset[:10000]\n",
    "n       = len(dataset)\n",
    "n_train = int(n*0.6)\n",
    "n_val   = int(n*0.2)\n",
    "dataset_train = dataset[:n_train]\n",
    "dataset_val   = dataset[n_train:n_train+n_val]\n",
    "dataset_test  = dataset[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(tokenizer, dataset, max_length):\n",
    "    \"\"\"\n",
    "    データセットをデータローダに入力できる形に整形。\n",
    "    \"\"\"\n",
    "    dataset_for_loader = []\n",
    "    for sample in dataset:\n",
    "        text = sample['text']\n",
    "        entities = sample['entities']\n",
    "        encoding = tokenizer.encode_plus_tagged(\n",
    "            text, entities, max_length=max_length\n",
    "        )\n",
    "        encoding['intent_label'] = sample['intent']\n",
    "        encoding = { k: torch.tensor(v) for k, v in encoding.items() }\n",
    "        dataset_for_loader.append(encoding)\n",
    "    return dataset_for_loader\n",
    "\n",
    "# データセットの作成\n",
    "max_length = 128\n",
    "dataset_train_for_loader = create_dataset(\n",
    "    tokenizer, dataset_train, max_length\n",
    ")\n",
    "dataset_val_for_loader = create_dataset(\n",
    "    tokenizer, dataset_val, max_length\n",
    ")\n",
    "\n",
    "# データローダの作成\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train_for_loader, batch_size=32, shuffle=True\n",
    ")\n",
    "dataloader_val  = DataLoader(dataset_val_for_loader, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(entities_list, entities_predicted_list, type_id=None):\n",
    "    \"\"\"\n",
    "    正解と予測を比較し、モデルの固有表現抽出の性能を評価する。\n",
    "    type_idがNoneのときは、全ての固有表現のタイプに対して評価する。\n",
    "    type_idが整数を指定すると、その固有表現のタイプのIDに対して評価を行う。\n",
    "    \"\"\"\n",
    "    num_entities    = 0 # 固有表現(正解)の個数\n",
    "    num_predictions = 0 # BERTにより予測された固有表現の個数\n",
    "    num_correct     = 0 # BERTにより予測のうち正解であった固有表現の数\n",
    "    indices_incorrect = []\n",
    "    \n",
    "    # それぞれの文章で予測と正解を比較。\n",
    "    # 予測は文章中の位置とタイプIDが一致すれば正解とみなす。\n",
    "    counter = 0\n",
    "    for entities, entities_predicted \\\n",
    "        in zip(entities_list, entities_predicted_list):\n",
    "\n",
    "        if type_id:\n",
    "            entities = [ e for e in entities if e['type_id'] == type_id ]\n",
    "            entities_predicted = [ \n",
    "                e for e in entities_predicted if e['type_id'] == type_id\n",
    "            ]\n",
    "            \n",
    "        get_span_type = lambda e: (e['span'][0], e['type_id'])\n",
    "        set_entities = set( get_span_type(e) for e in entities )\n",
    "        set_entities_predicted = \\\n",
    "            set( get_span_type(e) for e in entities_predicted )\n",
    "\n",
    "        num_entities += len(entities)\n",
    "        num_predictions += len(entities_predicted)\n",
    "        num_correct += len( set_entities & set_entities_predicted )\n",
    "        \n",
    "        # debug\n",
    "        if(len(set_entities) != len( set_entities & set_entities_predicted )):\n",
    "            indices_incorrect.append(counter)\n",
    "        #    print(set_entities)\n",
    "        #    print(set_entities_predicted)\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    # 指標を計算\n",
    "    precision = num_correct/num_predictions # 適合率\n",
    "    recall = num_correct/num_entities # 再現率\n",
    "    f_value = 2*precision*recall/(precision+recall) # F値\n",
    "\n",
    "    result = {\n",
    "        'num_entities': num_entities,\n",
    "        'num_predictions': num_predictions,\n",
    "        'num_correct': num_correct,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f_value': f_value\n",
    "    }\n",
    "\n",
    "    #print(indices_incorrect)\n",
    "    return result\n",
    "\n",
    "def run_model(session, dataset):\n",
    "    intents_list            = [] # 正解インテントを追加している\n",
    "    intents_predicted_list  = [] # 分類されたインテントを追加していく\n",
    "    entities_list           = [] # 正解の固有表現を追加していく\n",
    "    entities_predicted_list = [] # 抽出された固有表現を追加していく\n",
    "\n",
    "    for sample in tqdm(dataset):\n",
    "        text = sample['text']\n",
    "        encoding, spans = tokenizer.encode_plus_untagged(\n",
    "            text, return_tensors='pt'\n",
    "        )\n",
    "        encoding = { k: v.cpu() for k, v in encoding.items() } \n",
    "        inputs = {\n",
    "            \"input_ids\"      : encoding[\"input_ids\"     ].cpu().numpy(),\n",
    "            \"attention_mask\" : encoding[\"attention_mask\"].cpu().numpy(),\n",
    "            \"token_type_ids\" : encoding[\"token_type_ids\"].cpu().numpy()\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_loss, logits_intent, logits_slot = session.run( None, inputs)\n",
    "            scores_intent = logits_intent\n",
    "            scores_slots  = logits_slot[0]\n",
    "\n",
    "        # 分類スコアを固有表現に変換する\n",
    "        entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
    "            text, scores_slots, spans\n",
    "        )\n",
    "\n",
    "        intents_list.append(sample['intent'])\n",
    "        intents_predicted_list.append(scores_intent.argmax(-1)[0])\n",
    "        entities_list.append(sample['entities'])\n",
    "        entities_predicted_list.append( entities_predicted )\n",
    "    \n",
    "    return intents_list, intents_predicted_list, entities_list, entities_predicted_list\n",
    "\n",
    "def run_onnx_evaluation(session, dataset):\n",
    "    outputs = run_model(session, dataset)\n",
    "    intents_list            = outputs[0]\n",
    "    intents_predicted_list  = outputs[1]\n",
    "    entities_list           = outputs[2]\n",
    "    entities_predicted_list = outputs[3]\n",
    "    \n",
    "    # インテント分類スコア\n",
    "    counter = 0.0\n",
    "    for pred, truth in zip(intents_predicted_list, intents_list):\n",
    "        counter += float(pred == truth)\n",
    "    print('intent classification accuracy = ', counter/len(intents_list))\n",
    "    # 固有表現抽出スコア\n",
    "    print(evaluate_model(entities_list, entities_predicted_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_fp32 = ort.InferenceSession(\n",
    "    ONNX_FILE_PATH,\n",
    "    providers=['CUDAExecutionProvider']\n",
    ")\n",
    "run_onnx_evaluation(sess_fp32, dataset_test)\n",
    "del sess_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_i8 = ort.InferenceSession(\n",
    "    ONNX_INT8_FILE_PATH,\n",
    "    providers=['TensorrtExecutionProvider']\n",
    ")\n",
    "run_onnx_evaluation(sess_i8, dataset_test)\n",
    "del sess_i8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = unicodedata.normalize('NFKC', '会議室にある黄色い電灯の火を点灯してくださいな')\n",
    "encoding, spans = tokenizer.encode_plus_untagged(\n",
    "    text, return_tensors='pt'\n",
    ")\n",
    "encoding = { k: v.cpu() for k, v in encoding.items() } \n",
    "\n",
    "inputs = {\n",
    "    \"input_ids\": encoding[\"input_ids\"].cpu().numpy(),\n",
    "    \"attention_mask\": encoding[\"attention_mask\"].cpu().numpy(),\n",
    "    \"token_type_ids\": encoding[\"token_type_ids\"].cpu().numpy()\n",
    "}\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    ONNX_INT8_FILE_PATH,\n",
    "    providers=['CUDAExecutionProvider']\n",
    ")\n",
    "total_loss, logits_intent, logits_slot = ort_session.run( None, inputs)\n",
    "scores_intent = logits_intent\n",
    "scores_slots  = logits_slot[0]\n",
    "\n",
    "# Intent 分類スコアを Intent に変換する\n",
    "intent = scores_intent.argmax(-1)[0]\n",
    "# Slot 分類スコアを固有表現に変換する\n",
    "entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
    "    text, scores_slots, spans\n",
    ")\n",
    "\n",
    "print(\"入力\",text)\n",
    "print(\"予測 intent  :\", intent)\n",
    "print(\"予測 entities:\", json.dumps(entities_predicted, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
