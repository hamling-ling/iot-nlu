{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "\n",
    "# local modules\n",
    "from ner_tokenizer_bio import NER_tokenizer_BIO\n",
    "from bert_for_token_classification_pl import BertForTokenClassification_pl\n",
    "\n",
    "# 日本語学習済みモデル\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path='./model/epoch=4-step=660.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能評価\n",
    "model = BertForTokenClassification_pl.load_from_checkpoint(\n",
    "    best_model_path\n",
    ")\n",
    "bert_tc = model.bert_tc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スロットの種類数 (COL=1, COLLTDEV=2, LOC=3, ONOFFDEV=4, OPENABLE=5, TEMPDEV=6, TEMPERTURE_NUM=7, THMDEV=8)\n",
    "NUM_ENTITY_TYPE = 8\n",
    "\n",
    "# トークナイザのロード\n",
    "# 固有表現のカテゴリーの数`num_entity_type`を入力に入れる必要がある。\n",
    "tokenizer = NER_tokenizer_BIO.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_entity_type=NUM_ENTITY_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 個別に実行\n",
    "entities           = [] # 正解の固有表現\n",
    "entities_predicted = [] # 抽出された固有表現\n",
    "\n",
    "text = unicodedata.normalize('NFKC', '会議室にある黄色い電灯の火を点灯してくださいな')\n",
    "\n",
    "encoding, spans = tokenizer.encode_plus_untagged(\n",
    "    text, return_tensors='pt'\n",
    ")\n",
    "encoding = { k: v.cuda() for k, v in encoding.items() } \n",
    "\n",
    "with torch.no_grad():\n",
    "    output = bert_tc(**encoding)\n",
    "    # tuple の 2 番めには tuple(logits_intent, logits_slot) が入っている\n",
    "    logits_tuple  = output[1]\n",
    "    logits_intent = logits_tuple[0]\n",
    "    logits_slot = logits_tuple[1][0]\n",
    "    scores_intent = logits_intent.cpu().numpy()\n",
    "    scores_slots  = logits_slot.cpu().numpy().tolist()\n",
    "\n",
    "# Intent 分類スコアを Intent に変換する\n",
    "intent = scores_intent.argmax(-1)[0]\n",
    "# Slot 分類スコアを固有表現に変換する\n",
    "entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
    "    text, scores_slots, spans\n",
    ")\n",
    "\n",
    "print(\"入力\",text)\n",
    "print(\"予測 intent  :\", intent)\n",
    "print(\"予測 entities:\", json.dumps(entities_predicted, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
