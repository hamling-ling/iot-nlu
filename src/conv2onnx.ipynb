{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "from ner_tokenizer_bio import NER_tokenizer_BIO\n",
    "from bert_for_token_classification_pl import BertForTokenClassification_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_PATH='./model/epoch=4-step=660.ckpt'\n",
    "TOKENIZER_PATH = './model/iot-nlu-tokenizer'\n",
    "ONNX_FILE_PATH = './model/iot-nlu.onnx'\n",
    "\n",
    "# インテントの種類数 (None=0, LED_ON=1, LED_OFF=2, READ_THERMO=3, OPEN=4, CLOSE=5, SET_TEMP=6)\n",
    "NUM_INTENT_LABELS = 7\n",
    "\n",
    "# スロットの種類数 (COL=1, COLLTDEV=2, LOC=3, ONOFFDEV=4, OPENABLE=5, TEMPDEV=6, TEMPERTURE_NUM=7, THMDEV=8)\n",
    "NUM_ENTITY_TYPE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザのロード\n",
    "# 固有表現のカテゴリーの数`num_entity_type`を入力に入れる必要がある。\n",
    "tokenizer = NER_tokenizer_BIO.from_pretrained(\n",
    "    TOKENIZER_PATH,\n",
    "    num_entity_type=NUM_ENTITY_TYPE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JointBert from ckpt\n",
    "model = BertForTokenClassification_pl.load_from_checkpoint(\n",
    "    BEST_MODEL_PATH\n",
    ")\n",
    "model.eval()\n",
    "model.bert_tc.eval()\n",
    "bert=model.bert_tc\n",
    "bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 個別に実行\n",
    "entities           = [] # 正解の固有表現\n",
    "entities_predicted = [] # 抽出された固有表現\n",
    "\n",
    "text = unicodedata.normalize('NFKC', '会議室にある黄色い電灯の火を点灯してくださいな')\n",
    "\n",
    "encoding, spans = tokenizer.encode_plus_untagged(\n",
    "    text, return_tensors='pt', max_length=128\n",
    ")\n",
    "encoding = { k: v.cuda() for k, v in encoding.items() } \n",
    "\n",
    "with torch.no_grad():\n",
    "    print(encoding)\n",
    "    total_loss, logits_intent, logits_slot = bert(**encoding)\n",
    "    scores_intent = logits_intent.cpu().numpy()\n",
    "    scores_slots  = logits_slot[0].cpu().numpy().tolist()\n",
    "    print(f'total_loss\\n\\ttype={type(total_loss)}\\n\\tsize={total_loss.size}, val={total_loss}')\n",
    "    print(f'logits_intent\\n\\ttype={type(logits_intent)}\\n\\tshape={logits_intent.shape}\\n\\tval={logits_intent}')\n",
    "    print(f'logits_slot\\n\\ttype={type(logits_slot)}\\n\\tshape={logits_slot.shape}\\n\\tval={logits_slot}')\n",
    "\n",
    "# Intent 分類スコアを Intent に変換する\n",
    "intent = scores_intent.argmax(-1)[0]\n",
    "# Slot 分類スコアを固有表現に変換する\n",
    "entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
    "    text, scores_slots, spans\n",
    ")\n",
    "\n",
    "print(\"入力\",text)\n",
    "print(\"予測 intent  :\", intent)\n",
    "print(\"予測 entities:\", json.dumps(entities_predicted, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids      = encoding[\"input_ids\"]\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "token_type_ids = encoding[\"token_type_ids\"]\n",
    "print(input_ids)\n",
    "print(attention_mask)\n",
    "print(token_type_ids)\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "_ = bert.eval()\n",
    "torch.onnx.export(\n",
    "    bert.cpu(),\n",
    "    tuple([input_ids.cpu(), attention_mask.cpu(), token_type_ids.cpu()]),\n",
    "    ONNX_FILE_PATH,\n",
    "    export_params=True, opset_version=11,\n",
    "    input_names = ['input_ids', 'attention_mask', 'token_type_ids'],\n",
    "    output_names = ['total_loss', 'intent_logits', 'slot_logits']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "encoding, spans = tokenizer.encode_plus_untagged(\n",
    "    text, max_length=128, return_tensors='pt'\n",
    ")\n",
    "encoding = { k: v.cpu() for k, v in encoding.items() } \n",
    "\n",
    "inputs = {\n",
    "    \"input_ids\": input_ids.cpu().numpy(),\n",
    "    \"attention_mask\": attention_mask.cpu().numpy(),\n",
    "    \"token_type_ids\": token_type_ids.cpu().numpy()\n",
    "}\n",
    "\n",
    "ort_session = ort.InferenceSession(\n",
    "    ONNX_FILE_PATH,\n",
    "    providers=['CUDAExecutionProvider']\n",
    ")\n",
    "total_loss, logits_intent, logits_slot = ort_session.run( None, inputs)\n",
    "scores_intent = logits_intent\n",
    "scores_slots  = logits_slot[0]\n",
    "\n",
    "print(f'total_loss\\n\\ttype={type(total_loss)}\\n\\tsize={total_loss.size}, val={total_loss}')\n",
    "print(f'logits_intent\\n\\ttype={type(logits_intent)}\\n\\tshape={logits_intent.shape}\\n\\tval={logits_intent}')\n",
    "print(f'logits_slot\\n\\ttype={type(logits_slot)}\\n\\tshape={logits_slot.shape}\\n\\tval={logits_slot}')\n",
    "\n",
    "# Intent 分類スコアを Intent に変換する\n",
    "intent = scores_intent.argmax(-1)[0]\n",
    "# Slot 分類スコアを固有表現に変換する\n",
    "entities_predicted = tokenizer.convert_bert_output_to_entities(\n",
    "    text, scores_slots, spans\n",
    ")\n",
    "\n",
    "print(\"入力\",text)\n",
    "print(\"予測 intent  :\", intent)\n",
    "print(\"予測 entities:\", json.dumps(entities_predicted, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify onnx\n",
    "!onnxsim model/iot-nlu.onnx model/iot-nlu-sim.onnx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
